{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Twitter for 50K Tweets\n",
    "_<b>Author:</b> Raffy Santayana_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "The aftermath of Hurricane Sandy led over 8 million US people without power<sub>[1](https://www.huffpost.com/entry/hurricane-sandy-power-outage-map-infographic_n_2044411)</sub>. According to [energy.gov](https://www.energy.gov/articles/hurricane-sandy-noreaster-situation-reports), everyone who was able to recieve electricity after the storm has had their electricity restored by December 3, leaving 26,000 people in New York and New Jersey without power. One of the methods of detecting power outages at this time was by utilizing [smart meters and Advanced Meter Infrastructures (AMI)](https://openei.org/wiki/Definition:Outage_Detection/Reporting). The problem is that these systems will not be fully implemented until 2030 due to high cost of production<sub>[2](http://people.stern.nyu.edu/kbauman/research/papers/2015_KBauman_WITS.pdf)</sub>. As an alternative method of detecting these outages, we will be using natural language processsing techniques such as web embedding to analyze various posts from a social media platform, Twitter. When analyzing these posts, we hope to classify the location that the tweet was sent from as an area either with or without power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import GetOldTweets3 as got\n",
    "import time as t\n",
    "import datetime\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "max_tweets = 50_000\n",
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(\"'blackout' OR 'blackouts' OR 'outage' OR 'outages' OR 'power outage' OR 'pwr out' OR 'no pwr' OR 'no power' -filter:retweets\")\\\n",
    "                                           .setSince(\"2014-01-01\")\\\n",
    "                                           .setUntil(\"2019-09-02\")\\\n",
    "                                           .setMaxTweets(max_tweets)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tweets = list()\n",
    "start_time = datetime.datetime.now()\n",
    "for i in max_tweets:\n",
    "    print(f'sleeping...')\n",
    "    t.sleep(1)\n",
    "    pull_stime = datetime.datetime.now()\n",
    "    tweets.append(got.manager.TweetManager.getTweets(tweetCriteria_2014)[i])\n",
    "    print(f'{datetime.datetime.now() - pull_stime} to complete pull')\n",
    "    print(f'Got tweet {i}')\n",
    "print(f'{datetime.datetime.now() - start_time} to complete')```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tweet_id, username, text, date =list()\n",
    "for tweet in tweets_collected:\n",
    "    tweet_id.append(tweet.id)\n",
    "    username.append(tweet.username)\n",
    "    text.append(tweet.text)\n",
    "    date.append(tweet.date)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_tweets = pd.DataFrame(data = {'id': tweet_id,\n",
    "                     'username': username,\n",
    "                     'text': text,\n",
    "                     'timestamp': date})```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_tweets.to_csv('./data/tweets.csv')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
